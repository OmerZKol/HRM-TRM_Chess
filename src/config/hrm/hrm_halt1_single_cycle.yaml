# Configuration for HRM Chess Model with halt_max_steps=1
# Model: ChessNNet (HierarchicalReasoningModel_ACTV1) - Single-step reasoning

# Training parameters
batch_size: 512
learning_rate: 0.0001
epochs: 20

name: "hrm_halt1_single_cycle"

# Data sampling
sample_rate: 1  # Use all data (set to higher value for faster training with less data)

# Training optimizations
num_workers: 4  # Number of parallel data loading workers (0 = single-threaded)
use_amp: true  # Use Automatic Mixed Precision training (faster on modern GPUs)
gradient_accumulation_steps: 1  # Accumulate gradients over N steps (effective_batch = batch_size * N)

# Loss weights
policy_loss_weight: 1.0
value_loss_weight: 1.0
moves_left_loss_weight: 0.01

# Model architecture
model_type: hrm

# HRM specific parameters
hrm_config:
  seq_len: 64  # Input sequence length (number of tokens)
  # Reasoning cycles
  H_cycles: 1
  L_cycles: 1
  H_layers: 2
  L_layers: 2
  
  # Model dimensions
  hidden_size: 256
  expansion: 2.0
  num_heads: 8

  # Positional encodings
  pos_encodings: rope
  rope_theta: 10000.0

  # Halting configuration - SINGLE STEP
  halt_max_steps: 1
  halt_exploration_prob: 0.0

  # Chess-specific configuration
  square_feature_dim: 112

  # Output heads
  use_move_prediction: true
  use_value_prediction: true
  use_moves_left_prediction: true
  move_prediction_from_token: 0
  value_prediction_from_token: 0
  moves_left_from_token: 0

  # Positional encoding style
  arc_encoding: true  # concat pos_enc with features
  pos_enc_dim: 16

  # TensorFlow-style heads for spatial processing
  use_tensorflow_style_heads: true
  use_attention_policy: true
  value_embedding_size: 32
  moves_embedding_size: 8

  # Data type
  forward_dtype: bfloat16