# Configuration for HRM Chess Model with halt_max_steps=10
# Model: ChessNNet (HierarchicalReasoningModel_ACTV1) - Multi-step reasoning

# Training parameters
batch_size: 512
learning_rate: 0.0001
epochs: 80

name: "hrm_halt4"

# Data sampling
sample_rate: 1  # Use all data (set to higher value for faster training with less data)

# Training optimizations
num_workers: 4  # Number of parallel data loading workers (0 = single-threaded)
use_amp: true  # Use Automatic Mixed Precision training (faster on modern GPUs)
gradient_accumulation_steps: 1  # Accumulate gradients over N steps (effective_batch = batch_size * N)

# Loss weights
policy_loss_weight: 1.0
value_loss_weight: 1.0
moves_left_loss_weight: 0.01

# Model architecture
model_type: hrm
board_x: 8
board_y: 8
action_size: 1858

# HRM specific parameters
hrm_config:
  seq_len: 64  # Input sequence length (number of tokens)
  # Reasoning cycles
  H_cycles: 2
  L_cycles: 2
  H_layers: 2
  L_layers: 2

  # Model dimensions
  hidden_size: 512
  expansion: 2.0
  num_heads: 8
  action_size: 1858

  # Positional encodings
  pos_encodings: rope
  rope_theta: 10000.0

  # Halting configuration - MULTI-STEP with adaptive computation
  halt_max_steps: 4
  halt_exploration_prob: 0.1

  # Chess-specific configuration
  square_feature_dim: 112

  # Output heads
  use_move_prediction: true
  use_value_prediction: true
  use_moves_left_prediction: true
  move_prediction_from_token: 0
  value_prediction_from_token: 0
  moves_left_from_token: 0

  # TensorFlow-style heads for spatial processing
  use_tensorflow_style_heads: true
  use_attention_policy: true
  value_embedding_size: 32
  moves_embedding_size: 8

  # Data type
  forward_dtype: bfloat16